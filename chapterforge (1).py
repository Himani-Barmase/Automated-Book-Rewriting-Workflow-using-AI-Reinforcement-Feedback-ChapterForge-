# -*- coding: utf-8 -*-
"""ChapterForge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_5KN8KUVexVr9ijLtDu0WbTMpu55oEnN

# ChapterForge
"""

# Install Libraries
!pip install requests
!pip install beautifulsoup4

#Import Tools
import requests
from bs4 import BeautifulSoup

def fetch_chapter_text(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    content_div = soup.find('div', {'class': 'mw-parser-output'})
    if not content_div:
        return "‚ùå Could not find main content."

    paragraphs = content_div.find_all('p')
    chapter_text = "\n\n".join(p.get_text() for p in paragraphs)

    with open("Chapter1_Text.txt", "w", encoding="utf-8") as f:
        f.write(chapter_text)

    return chapter_text

# Use the Function with Book Chapter URL

url = "https://en.wikisource.org/wiki/The_Gates_of_Morning/Book_1/Chapter_1"

text = fetch_chapter_text(url)

print("‚úÖ Chapter fetched successfully!")
print(text[:1000])  # Preview first 1000 characters

"""Step 2: AI "Spin" the Chapter"""

!pip uninstall openai -y
!pip install --upgrade openai

from google.colab import files
uploaded = files.upload()

!pip install PyPDF2

# Step 1: Import PyPDF2
from PyPDF2 import PdfReader

# Step 2: Load your PDF file
reader = PdfReader("The_Gates_of_Morning_Book_1_Chapter_1.pdf")

# Step 3: Extract text
chapter_text = ""
for page in reader.pages:
    text = page.extract_text()
    if text:
        chapter_text += text + "\n"

# Step 4: Print preview
print("‚úÖ Extracted Text Preview:\n")
print(chapter_text[:1000])  # Display first 1000 characters only

!pip install transformers accelerate

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

# Free model from HuggingFace (no key needed)
model_name = "mistralai/Mistral-7B-Instruct-v0.1"

# Load model and tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto")

# Create pipeline
pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)

# Generate text
response = pipe("Explain AI in simple words:", max_new_tokens=100)
print(response[0]["generated_text"])

from transformers import pipeline

# Load an open-access model
generator = pipeline("text-generation", model="EleutherAI/gpt-neo-1.3B")

# Generate a response
prompt = "Explain how quantum computers work in simple terms."
output = generator(prompt, max_length=100, do_sample=True, temperature=0.7)

print(output[0]['generated_text'])

#used the gpt2 model (a general-purpose language model) to generate text based on the prompt:
#"Explain how quantum computers work in simple terms."
#It generated a response, but started outputting random-looking C code, which is common with small models like GPT-2 when the prompt isn't tightly constrained.

# ‚úÖ Install and import dependencies
!pip install transformers --quiet

from transformers import pipeline, set_seed
import torch

# ‚úÖ Load the model locally (FREE, no API key required)
generator = pipeline("text-generation", model="gpt2")

# ‚úÖ Your input prompt
full_prompt = "Explain how quantum computers work in simple terms."

# ‚úÖ Generate text
response = generator(full_prompt,
                     max_new_tokens=150,
                     do_sample=True,
                     temperature=0.7)

# ‚úÖ Display result
print(response[0]['generated_text'])

#Chapter Rewriting
from transformers import pipeline

# Load AI Writer (you can switch to any other local model too)
generator = pipeline("text-generation", model="tiiuae/falcon-7b-instruct", device="cpu")

# Sample content (replace this with your scraped chapter content)
original_text = """
The sea was a dark blue floor of satin spangled with sunlight. Not a ripple moved the broad surface.
The schooner lay becalmed, her sails flapping idly, her reflection vivid as herself.
"""

# Prompt for AI Writing (Creative Rewriting)
prompt = f"""Rewrite the following text in a more vivid and captivating storytelling style, without changing the meaning. Make it more engaging like a novel:

--- START ---
{original_text}
--- END ---
"""

# Generate rewritten version
response = generator(prompt, max_new_tokens=500, do_sample=True, temperature=0.7)

print("üìù Rewritten Chapter Version:\n")
print(response[0]['generated_text'])

#Reviewer AI (Simulated Text Scoring)
#fine-tune this or replace it with a custom-trained critic model for richer feedback.
from transformers import pipeline

# Load a sentiment-analysis-like model for review (you can switch models later)
reviewer = pipeline("text-classification", model="mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis", device="cpu")

# Rewritten text from previous step (or use your own)
rewritten_text = response[0]['generated_text']

# Prompt-style instruction for reviewer
review_prompt = f"""
Please evaluate the following rewritten passage based on the following:
1. Clarity of narration
2. Engaging language
3. Rich vocabulary
4. Narrative coherence

Text:
{rewritten_text}

Your evaluation score (1 to 5 stars) and key feedback summary:
"""

# Send to model for simulated review
review = reviewer(review_prompt)

# Show output
print("üîç Reviewer Feedback:\n")
print(f"Label: {review[0]['label']}, Confidence: {review[0]['score']:.2f}")

#Human Feedback Interface (Rating System)
def get_human_feedback(text):
    print("\nüìù AI Output:\n")
    print(text)
    rating = int(input("\n‚≠ê Rate this output (1‚Äì5): "))
    comment = input("üí¨ Feedback on this version: ")
    return rating, comment

#Simulate Reward-Based Fine-Tuning
def adjust_prompt(prompt, rating, comment):
    if rating >= 4:
        return prompt  # Keep same prompt if feedback is good
    else:
        # Refine prompt based on feedback
        refined_prompt = prompt + f"\n# Human feedback: {comment}\n# Improve based on above feedback."
        return refined_prompt

#AI Rewrites with Adjusted Prompt
def generate_rewrite(generator, prompt):
    output = generator(prompt, max_new_tokens=500, do_sample=True, temperature=0.7)
    return output[0]['generated_text']

# RL-like Iteration Loop

# Sample content
original_text = """The sea was a dark blue floor of satin spangled with sunlight..."""

# Initial prompt
base_prompt = f"""Rewrite the following text in a more vivid and captivating storytelling style, without changing the meaning. Make it more engaging like a novel:

--- START ---
{original_text}
--- END ---
"""

# Use GPT-2 pipeline
from transformers import pipeline
generator = pipeline("text-generation", model="gpt2")

# Define required functions
def generate_rewrite(generator, prompt):
    output = generator(prompt, max_length=300, do_sample=True, pad_token_id=50256)
    return output[0]['generated_text']

def get_human_feedback(text):
    # Dummy feedback (replace with actual review logic if needed)
    return 7.5, "Use simpler words and improve flow."

def adjust_prompt(base_prompt, rating, feedback):
    return base_prompt + f"\n\n[Feedback: {feedback} | Rating: {rating}/10]"

# Start loop
current_prompt = base_prompt

for i in range(3):  # 3 iterations
    print(f"\nüîÅ Iteration {i+1}")
    ai_output = generate_rewrite(generator, current_prompt)
    rating, feedback = get_human_feedback(ai_output)
    current_prompt = adjust_prompt(base_prompt, rating, feedback)

#build a Semantic Version Control + Agent Pipeline system for your AI-generated chapters.

!pip install chromadb sentence-transformers

#Setup ChromaDB for Semantic Storage
import chromadb
from chromadb.config import Settings

client = chromadb.Client(Settings(anonymized_telemetry=False))

collection = client.get_or_create_collection(name="chapter_versions")

#Store Rewritten Chapters with Metadata
from sentence_transformers import SentenceTransformer

# Load embedding model
embedder = SentenceTransformer("all-MiniLM-L6-v2")

def save_version(version_id, chapter_text, feedback="", rating=0):
    embedding = embedder.encode(chapter_text).tolist()

    collection.add(
        ids=[version_id],
        documents=[chapter_text],
        embeddings=[embedding],
        metadatas=[{"feedback": feedback, "rating": rating}]
    )
    print(f"‚úÖ Saved: {version_id}")

#Search Semantically Similar Versions
def search_similar(text, top_k=3):
    embedding = embedder.encode(text).tolist()
    results = collection.query(query_embeddings=[embedding], n_results=top_k)

    print("üîç Similar Versions:\n")
    for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
        print(f"‚Ä¢ {doc[:150]}...")
        print(f"  üîπ Feedback: {meta['feedback']} | Rating: {meta['rating']}\n")

#Agent Pipeline Structure (Writer ‚Üí Reviewer ‚Üí Editor)
def writer_agent(text):
    # Use your text-generation pipeline here
    return generator(f"Rewrite: {text}", max_new_tokens=300)[0]['generated_text']

def reviewer_agent(text):
    # Use sentiment, style, grammar checkers or LLM feedback
    return "Engaging narrative. Use simpler words in places.", 7.5

def editor_agent(text):
    # Could run grammar tool or slight rephrasing
    return text.replace("becalmed", "still and silent")

for i in range(3):  # 3 iterations
    print(f"\nüîÅ Iteration {i+1}")
    ai_output = generate_rewrite(generator, current_prompt)

    # Save versioned output
    with open(f"rewritten_output_v{i+1}.txt", "w") as f:
        f.write(ai_output)

    rating, feedback = get_human_feedback(ai_output)

    # Save feedback log
    with open("feedback_log.txt", "a") as f:
        f.write(f"Iteration {i+1} - Rating: {rating}, Feedback: {feedback}\n")

    current_prompt = adjust_prompt(base_prompt, rating, feedback)

import os
print(os.getcwd())

from google.colab import files
files.download("rewritten_output_v1.txt")
files.download("rewritten_output_v2.txt")
files.download("rewritten_output_v3.txt")
files.download("feedback_log.txt")

with open(f"rewritten_output_v{i+1}.txt", "w") as f:
    f.write(ai_output)

import os
for i in range(1, 4):
    print(os.path.exists(f"rewritten_output_v{i}.txt"))
print(os.path.exists("feedback_log.txt"))



"""Project Overview

What it is:

An AI-powered workflow that scrapes book chapters, rewrites them creatively using large language models, refines them through human and AI feedback, and tracks versions with semantic search ‚Äî all enhanced with a reinforcement learning-style loop.

Why it‚Äôs useful:

It reduces manual rewriting effort, improves creative quality via feedback, and introduces automation into editorial pipelines for writers, editors, and publishers.

How it helps:

It provides a structured, repeatable system for producing high-quality, AI-assisted content with human oversight, version control, and reward-driven iteration.

üõ†Ô∏è Step-by-Step Workflow

Step 1: Scrape Chapter from Wikisource
Scrapes the content of a chapter from a public domain book URL using requests and BeautifulSoup, then saves it as a plain text file.


Step 2: Extract Text from PDF (Alternative Input Mode)

Allows users to extract chapter content from a PDF using PyPDF2 if they prefer uploading instead of web scraping.


Step 3: AI Rewriting of Chapter (AI Writer)

Uses Hugging Face language models like GPT-2, Falcon, or GPT-Neo to rewrite the text in a more vivid, novel-style format without changing its meaning.


Step 4: AI Review & Scoring (AI Reviewer)

A sentiment or classification model simulates reviewing the rewritten content based on storytelling quality, clarity, and vocabulary, assigning a star rating.


Step 5: Human-in-the-Loop Feedback
Displays the AI-generated output to a human who rates the text (1‚Äì5 stars) and provides qualitative feedback used in the next rewrite cycle.


Step 6: RL-Based Iterative Rewriting

Simulates a reinforcement learning loop by adjusting the prompt based on human feedback and re-generating improved versions of the chapter in multiple iterations.


Step 7: Semantic Version Control with ChromaDB
Stores each rewritten version in a vector database using ChromaDB and SentenceTransformers, allowing semantic search and retrieval of similar or better versions.


Step 8: Agent Pipeline (Writer ‚Üí Reviewer ‚Üí Editor)

Implements a modular AI agent flow: the Writer rewrites, the Reviewer scores, and the Editor optionally refines grammar or structure. Each agent functions independently.


Step 9: Export Rewritten Versions

Saves each iteration (v1, v2, v3) of the rewritten chapter to text files for download and comparison, preserving the creative history of the content.


Step 10: Feedback Logging for Reward Loop

Appends every feedback and rating from the human reviewer into a feedback_log.txt file for auditability, tracking improvement, and future model fine-tuning.


Step 11: Semantic Search for Past Versions

Enables searching for previous rewritten chapters that are similar in meaning but different in wording, using vector similarity ‚Äî useful for refining or comparing styles.
"""

